---
title: Home
isHomepage: true
homepageDescription: 'As a Responsible AI Engineer at Microsoft, I work on the AI Red Team to identify vulnerabilities of generative AI systems in terms of AI safety and security. A huge part of this is building and maintaining our open source AI Red Teaming tookit <a href="https://github.com/Azure/PyRIT">PyRIT</a>. I am also a maintainer of the <a href="https://fairlearn.github.io">Fairlearn</a> project.'
resume:
    timeline:
      - timePeriod: "November 2023 - present"
        location: "Remote (WA)"
        logo: <img src="../images/msft.svg" alt="Microsoft logo" height="40px" class="left">
        title: "Responsible AI Engineer on the AI Red Team at Microsoft"
        descriptions:
          - '<iframe width="560" height="315" src="https://www.youtube.com/embed/oehEhQ93HiM?si=Iyp9nnl_k5uRoJRm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen class="center"></iframe><br><b>November 2025</b>: I spoke about <em>Red Teaming AI: Getting Started with PyRIT for Safer Generative AI Systems</em> at PyData Seattle!'
          - '<img src="../images/blind_goal_directedness_paper.png" alt="Overview graphic of the pre-print including examples of blind goal-directedness in computer-use agents, the benchmark design, as well as evaluation and findings" width="60%" class="center"><br><b>October 2025</b>: We published a new pre-print based on Erfan Shayegani&#x27;s summer internship. It is called "<a href="https://arxiv.org/abs/2510.01670">Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness</a>." This was a collaboration between the AI Red Team and our friends at Microsoft Research AI Frontiers.'
          - '<img src="../images/8_lessons_airt.webp" alt="The header image of the Microsoft blog post saying 8 lessons from the front lines of AI red teaming" width="40%" class="center"><br><b>January 2025</b>: We published a new whitepaper titled "<a href="https://aka.ms/AIRTLessonsPaper">Lessons Learned from Red Teaming 100 Generative AI Products</a>" as described in <a href="https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/01/14/enhancing-ai-safety-insights-and-lessons-from-red-teaming/?msockid=3b9f50fd6689604c2c934393670361be">this Microsoft blog</a>.'
          - '<b>July 2024</b>: PyRIT was a key part of Phi-3 Safety Post-Training which is highlighted in the associated paper <a href="https://arxiv.org/abs/2407.13833">Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle</a>'
          - '<b>May 2024</b>: One of the highlights from my perspective was going to the Microsoft //Build conference in May to talk to customers about PyRIT. After just about eight (!) years at Microsoft this was my first //Build conference. My colleagues Tori Westerhoff and Pete Bryan did an amazing job talking about the work of the AI Red Team in <a href="https://build.microsoft.com/en-US/sessions/0106b5b1-d727-4240-bb2e-dea325cb8519?source=sessions">their session</a>.'
          - '<img src="../images/pyrit_raccoon_parrot.png" alt="The PyRIT project mascot, a raccoon named Roakey, in pirate clothes with a parrot on her shoulder." width="40%" class="center"><br><b>February 2024</b>: <a href="https://www.microsoft.com/en-us/security/blog/2024/02/22/announcing-microsofts-open-automation-framework-to-red-team-generative-ai-systems/?msockid=221eb3d972cd620f327ea74e7345632e">We released PyRIT</a>! Since then, we have been expanding its capabilities to allow for probing multimodal generative AI systems (rather than just text-based ones). Another focus area has been state-of-the-art attack techniques. This space moves pretty fast, but we jave added (or are in the process of adding) <a href="https://arxiv.org/abs/2310.08419">PAIR</a>, <a href="https://arxiv.org/abs/2312.02119">Tree of attacks with pruning</a>, <a href="https://arxiv.org/abs/2307.15043">GCG</a>, <a href="https://arxiv.org/abs/2404.01833">Crescendo</a>, <a href="https://www.microsoft.com/en-us/security/blog/2024/06/26/mitigating-skeleton-key-a-new-type-of-generative-ai-jailbreak-technique/?msockid=221eb3d972cd620f327ea74e7345632e">Skeleton Key</a>, and several others. Some of these are our own contributions, some of them happened via collaborations or contributions facilitated via the open source repository.'
          - '<b>November 2023</b>: I have joined the <a href="https://learn.microsoft.com/en-us/security/ai-red-team/">AI Red Team</a>. See these articles for some background <a href="https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/">[1]</a>, <a href="https://www.wired.com/story/microsoft-ai-red-team/">[2]</a>, and <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming">[3]</a>.'
      - timePeriod: "December 2021 - November 2023"
        location: "Remote (MA)"
        logo: <img src="../images/msft.svg" alt="Microsoft logo" height="40px" class="left">
        title: "Responsible AI Engineer on the Azure AI team at Microsoft"
        descriptions:
          - '<img src="../images/lasertag-pipeline.png" alt="A screenshot from the JMLR website showing the new Fairlearn paper title with authors." width="80%" class="center"><br><b>October 2023</b>: Our new paper is on ArXiv! Titled <a href="https://jmlr.org/papers/v24/23-0389.html">A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications</a>, it talks about some of the ways we have been evaluating LLMs. This was a joint effort of many teams at Microsoft and Microsoft Research. I am particularly happy with the emphasis on input from domain experts. This is merely a tool to help speed up evaluations, but the actual decisions about mitigations and whether a system is deployed remains (and should remain) with humans.'
          - '<b>August 2023</b>: The new <a href="https://jmlr.org/papers/v24/23-0389.html">Fairlearn paper</a> is now in the Journal for Machine Learning Research (Open Source Software section)!<img src="../images/JMLR.png" alt="A screenshot from the JMLR website showing the new Fairlearn paper title with authors." width="80%" class="center"><br>It captures our change from being a project under Microsoft governance to being a true open source project with open governance. As of today, half the maintainers are employed by Microsoft (including myself). Also, the focus of the project has shifted significantly since the original whitepaper. Back then, the Python toolkit was the main focus whereas now the educational materials are being prioritized. This aims to acknowledge the sociotechnical nature of fairness.'
          - '<img src="../images/rai-dashboard-release.png" alt="RAI dashboard view of error analysis tool" width="80%" class="center"><br><b>December 2021</b>: We released the <a href="https://blogs.microsoft.com/ai-for-business/building-ai-responsibly-from-research-to-practice/">Responsible AI dashboard</a>. As one of the key contributors on the engineering side I am really proud of this milestone. Of course, this is only where it really starts as we can now iterate on the first version. Make sure to <a href="https://responsibleaitoolbox.ai">try it</a> and leave some feedback! The functionality is better captured by the blog and website, but something not mentioned there that I am really excited about is that we pulled this off in the open <a href="https://github.com/microsoft/responsible-ai-toolbox">on GitHub</a>. That means anyone can see what goes into this, ask for features, or even contribute bugfixes. Doing impactful work is awesome, but seeing the recognition in the entire company takes this to a whole different level. For example, I have seen tweets about this by <a href="https://twitter.com/kevin_scott/status/1468279751785828353">Microsoft CTO Kevin Scott</a> and <a href="https://twitter.com/erichorvitz/status/1468286435052572678?s=20">Chief Scientific Officer Eric Horvitz</a>.'
      - timePeriod: "September 2021 - November 2021"
        location: "TÃ¼bingen, Germany"
        logo: <img src="../images/mpg.svg" alt="Max Planck logo" height="80px" class="left">
        title: 'Graduate student at the Max Planck Institute for Intelligent Systems'
      - timePeriod: "July 2017 - August 2021"
        location: "Cambridge, MA (until 2020), Bellevue, WA (2020-2021)"
        logo: <img src="../images/msft.svg" alt="Microsoft logo" height="40px" class="left">
        title: "Responsible AI Engineer on the Azure ML team at Microsoft"
        descriptions:
          - '<img src="../images/fairlearn-repo.PNG" alt="fairlearn repository" width="80%" class="center"><br><b>November 2019</b>: For a little while now I have been working on <a href="https://www.microsoft.com/en-us/AI/our-approach-to-ai">Responsible AI at Microsoft</a>. Now that <a href="https://myignite.techcommunity.microsoft.com/sessions/81147">Sarah Bird announced our tools at Ignite</a> I can finally point to our tools publicly. A lot of my time over the past months went into <a href="https://github.com/fairlearn/fairlearn">Fairlearn</a>, our open source toolkit for fairness assessment and unfairness mitigation. We just released v0.3.0, so there is a lot more to come in the next months. I will be in Vancouver for NeurIPS in December to demo our tools around fairness and interpretability. Talk to me if you will be there!'
          - '<img src="../images/abstraction-fairml.PNG" alt="Abstraction in Fairness-aware Machine Learning" width="80%" class="center"><br><b>November 2019</b>: Since fairness is tricky to get right we have been meeting bi-weekly as a Responsible AI reading group. Today I had the honor to lead the discussion about <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913">"Fairness and Abstraction in Sociotechnical Systems"</a> by Andrew D. Selbst, danah boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. I highly encourage everyone to read this paper to avoid the mentioned abstraction traps when building machine learning systems. Maybe this should be part of a mandatory checklist before releasing models... If you are interested in my slides you may download them <a href="https://github.com/romanlutz/romanlutz.github.io/blob/gh-pages/other/FairnessAndAbstractionInSociotechnicalSystems.pdf">here</a>.'
          - '<b>March 2018</b>: Participating at <a href="http://www.mitbreakingthemold.com/challenges/">MIT`s Breaking the Mold Hackathon for Inclusion</a> was truly a blessing. With so many truly difficult problems to tackle, it is fantastic to see all the ideas people came up with. Big shoutout to MIT for organizing this, Microsoft for the venue (and encouraging me to go!), and Amazon for sending two inspiring mentors for my team all the way from Seattle! Thanks also to my team for creating a creative environment where everybody could express their ideas. I learned a ton from all of you, and winning 3rd prize tops it all off. I hope everybody takes some time to think about Machine Learning Bias. With ML becoming increasingly prevalent, it is more important than ever to take bias into account.'
          - "<b>July 2017</b>: After a year on the Office team, I moved to the Azure Machine Learning team. We are building the infrastructure and services from scratch using lots of open source (e.g., Kubernetes, Linux, .NET core)."
      - timePeriod: "June 2016 - June 2017"
        location: "Cambridge, MA"
        logo: <img src="../images/msft.svg" alt="Microsoft logo" height="40px" class="left">
        title: "Software Engineer at Microsoft Office (Docs)"
        descriptions:
          - '<b>May 2017</b>: I participated in the <a href="https://www.eventbrite.com/e/new-england-machine-learning-hackathon-hacking-bias-in-ml-tickets-32951771636?aff=NEML">Hacking Bias in ML</a> workshop at Microsoft`s New England Research and Development Center (which happens to be my office, too). My group specifically looked at gender bias in text through word embeddings. We found lots of evidence of gender bias, e.g., some words are generally more used in connection with men ("smart"), some more with women ("lovely"). You can play around with the tool resulting from the workshop <a href="https://mdml.github.io/hacking-bias-in-word-choice/#">here</a>.'
          - "<b>June 2016</b>: I have joined the Docs team within Microsoft Office. We enhance collaboration capabilities through the Share feature in all Office apps."
      - timePeriod: "Fall 2015 - Spring 2016"
        location: "Amherst, MA"
        logo: <img src="../images/umass-amherst.png" alt="UMass Amherst logo" height="48px" class="left">
        title: "MS in Computer Science, Focus on Distributed Systems and ML"
        descriptions:
          - '<img src="../images/cache-networks-simulation-results.png" alt="Cache Networks Simulation Results" width="40%" class="center"><br>I had the pleasure of working as a Research Assistant in the <a href="http://www-net.cs.umass.edu/networks/people.html">Computer Networking Lab</a> with Professor <a href="https://www.cs.umass.edu/faculty/directory/towsley_donald">Don Towsley</a> and Professor <a href="http://www2.ic.uff.br/~arocha/">Antonio Rocha</a> on the Simulation of Cache Networks. The results still remain to be published, so I will write about it if that happens. Separately, I conducted experiments with cache networks for a graduate seminar on distributed systems. You can download my project report <a href="https://github.com/romanlutz/romanlutz.github.io/blob/gh-pages/other/CacheNetworkSimulation.pdf">here</a>.'
          - '<img src="../images/ccn.png" alt="Content Centric Networking" width="50%" class="center"><br><b>January 2016</b>: There are several NSF-funded Future Internet Architecture research projects in the US. Their focus is mostly on improving the scalability and efficiency. I am interested in how the different approaches affect (or do not affect) the privacy of users in comparison to the current Internet. My main focus was the feasibility of censorship circumvention. As an example, I picked Content-oriented Networking. See the full paper at <a href="https://arxiv.org/abs/1601.01278">arxiv.org/abs/1601.01278</a>.'
          - '<img src="../images/pete-carroll.jpg" alt="Pete Carroll - coach" width="30%" class="center"><br><b>January 2016</b>: Based on NFL game data we try to predict the outcome of a play in multiple different ways including Decision and Classification Trees, Nearest Neighbors, Naive Bayes, Linear Discriminant Analysis, Support Vector Machines and Regression, and Artificial Neural Networks. An application of this is the following: by plugging in various play options one could determine the best play for a given situation in real time. While the outcome of a play can be described in many ways we had the most promising results with a newly defined measure that we call "progress". We see this work as a first step to include predictive analysis into NFL playcalling. See the full paper at <a href="https://arxiv.org/abs/1601.00574">arxiv.org/abs/1601.00574</a>; in collaboration with Brendan Teich and Valentin Kassarnig.'
      - timePeriod: "June 2015 - August 2015"
        location: "Eschborn, Germany"
        logo: <img src="../images/cisco.png" alt="Cisco Systems logo" height="40px" class="left">
        title: "Systems Engineering Intern"
      - timePeriod: "Fall 2014 - Spring 2015"
        location: "Amherst, MA"
        logo: <img src="../images/umass-amherst.png" alt="UMass Amherst logo" height="48px" class="left">
        title: "Graduate Exchange Student"
        descriptions:
          - "I took part in Baden-W&#252;rttemberg Exchange between University of Ulm and University of Massachusetts Amherst."
          - '<img src="../images/thomas-rawls.jpg" alt="Thomas Rawls - player" width="40%" class="center"><br><b>May 2015</b>: New paper! The ubiquity of professional sports and specifically the NFL have lead to an increase in popularity for Fantasy Football. Users have many tools at their disposal: statistics, predictions, rankings of experts and even recommendations of peers. There are issues with all of these, though. Especially since many people pay money to play, the prediction tools should be enhanced as they provide unbiased and easy-to-use assistance for users. This paper provides and discusses approaches to predict Fantasy Football scores of Quarterbacks with relatively limited data. See the full paper at <a href="https://arxiv.org/abs/1505.06918">arxiv.org/abs/1505.06918</a>.'
      - timePeriod: "Fall 2011 - Summer 2014"
        location: "Ulm, Germany"
        logo: <img src="../images/uni-ulm.svg" alt="Uni Ulm logo" height="40px" class="left">
        title: "University of Ulm"
        descriptions:
          - 'After a year of studying in the Mathematics Bachelor`s program with a minor in Computer Science I decided to swap major and minor. I still graduated with a BSc in Computer Science with honors. The courses covered basics in Systems, AI, and Theory.'
          - '<img src="../images/alns.png" alt="Adaptive Large Neighborhood Search - Destory and Repair" width="50%" class="center"><br>The goal of my Bachelor`s thesis was to implement the Adaptive Large Neighborhood Search (ALNS) heuristic and possibly come up with improvements. ALNS was described first by S. Ropke and D. Pisinger and is based on P. Shaw`s Large Neighborhood Search. The idea is that some problems are difficult to solve with basic local search algorithms because of a tightly constrained search space. Small changes to a solution will rarely bring improvements. As a consequence, LNS and ALNS change larger parts based on different heuristics. For this thesis, I was awarded the innoWake Award 2015. <a href="http://www.innowake.com">innoWake</a> was a software modernization company based in Austin, TX and had a number of branch offices including one in Germany. They have since been acquired by Deloitte.'
          - '<img src="../images/graph.svg" alt="Graph from http://commons.wikimedia.org/wiki/File:Dinic_algorithm_Gf2.svg, public domain" width="50%" class="center"><br>As a teaching assistant for Prof. Jacobo Toran, Gunnar V&#246;lkel and Dominikus Kr&#252;ger, I explained the solutions to weekly assignments to a group of 20 students whose work I also graded. In addition to that, I often gave a review of the material presented in class. It made me very happy to see the attendance rate constantly high throughout the semester and especially the positive feedback at the end of the course.'
          - '<img src="../images/bees.jpg" alt="Bees from https://pixabay.com/en/queen-cup-honeycomb-honey-bee-337695/, CC0 Public Domain" width="60%" class="center"><br>We can observe many kinds of behavior of animals, bacteria etc. in nature where an adaption to the specific environment has taken place due to evolution. In a way, an optimization process has taken place. This idea is the basis for so-called nature-inspired metaheuristics. The Artificial Bee Colony (ABC) meta-heuristic by D. Karaboga is such a nature-inspired metaheuristic. It projects the foraging behavior of bees on an algorithm in order to solve optimization problems.'
          - '<img src="../images/traffic.jpg" alt="Traffic from https://pixabay.com/en/traffic-highway-lights-night-road-332857/, CC0 Public Domain" width="50%" class="center"><br>Under the guidance of Christian Spann, I read up on different ways to implement concurrent programs in Java, from Threads, Runnables and Executors to thread-safe versions of data structures. Finally, I presented the different approaches and techniques in a seminar talk.'

---
