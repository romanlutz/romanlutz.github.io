---
title: Home
isHomepage: true
homepageDescription: As a Responsible AI Engineer at Microsoft, I work on the AI Red Team to identify vulnerabilities of generative AI systems in terms of AI safety and security. A huge part of this is building and maintaining our open source AI Red Teaming tookit <a href="https://github.com/Azure/PyRIT">PyRIT</a>. I am also a maintainer of the <a href="https://fairlearn.github.io">Fairlearn</a> project.
resume:
  timeline:
  - timePeriod: November 2023 - present
    location: Remote (WA)
    logo: msft.svg
    logoAlt: Microsoft logo
    title: Responsible AI Engineer on the AI Red Team at Microsoft
    events:
    - date: November 2025
      title: PyData Seattle talk
      youtube: https://www.youtube.com/embed/oehEhQ93HiM?si=Iyp9nnl_k5uRoJRm
      description: 'I spoke about <em>Red Teaming AI: Getting Started with PyRIT for Safer Generative AI Systems</em> at PyData Seattle!'
    - date: October 2025
      title: Blind Goal-Directedness paper accepted at ICLR 2026
      image: blind_goal_directedness_paper.png
      imageAlt: Overview graphic of the pre-print including examples of blind goal-directedness in computer-use agents, the benchmark design, as well as evaluation and findings
      description: Our paper "<a href="https://arxiv.org/abs/2510.01670">Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness</a>" has been accepted at ICLR 2026! This was a collaboration between the AI Red Team and our friends at Microsoft Research AI Frontiers, based on Erfan Shayegani&#x27;s summer internship.
    - date: May 2025
      title: Build 2025 Lab
      image: build2025labcrew.jpg
      imageLayout: side-md
      imageAlt: The crew supporting our lab at the Microsoft Build conference 2025 called AI security testing with PyRIT
      description: After attending //Build for the first time last year, I co-presented the same lab on "AI security testing with PyRIT" twice, once with Rich Lundeen and once with Nina Chikanov. It was fun to see people try out PyRIT, learn about this new area, and get feedback. Shoutout to Sarah Young, Sydney Lister, Joylynn Kirui, Justin Song, and JP Hernandez for supporting the sessions.
    - date: April 2025
      title: Taxonomy of Failure Modes in Agentic AI
      description: Our new whitepaper "<a href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/Taxonomy-of-Failure-Mode-in-Agentic-AI-Systems-Whitepaper.pdf">Taxonomy of Failure Modes in Agentic AI Systems</a>" is out! For a high-level idea, check out <a href="https://www.microsoft.com/en-us/security/blog/2025/04/24/new-whitepaper-outlines-the-taxonomy-of-failure-modes-in-ai-agents/?msockid=025deda99e1e63193accfbd59fce6243">this Microsoft blog</a>.
    - date: January 2025
      title: Lessons from Red Teaming 100 GenAI Products
      image: 8_lessons_airt.webp
      imageLayout: side
      imageAlt: The header image of the Microsoft blog post saying 8 lessons from the front lines of AI red teaming
      description: We published a new whitepaper titled "<a href="https://aka.ms/AIRTLessonsPaper">Lessons Learned from Red Teaming 100 Generative AI Products</a>" as described in <a href="https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/01/14/enhancing-ai-safety-insights-and-lessons-from-red-teaming/?msockid=3b9f50fd6689604c2c934393670361be">this Microsoft blog</a>.
    - date: July 2024
      title: Phi-3 Safety Post-Training
      description: 'PyRIT was a key part of Phi-3 Safety Post-Training which is highlighted in the associated paper <a href="https://arxiv.org/abs/2407.13833">Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle</a>'
    - date: May 2024
      title: Microsoft //Build 2024
      description: One of the highlights from my perspective was going to the Microsoft //Build conference in May to talk to customers about PyRIT. After just about eight (!) years at Microsoft this was my first //Build conference. My colleagues Tori Westerhoff and Pete Bryan did an amazing job talking about the work of the AI Red Team in <a href="https://build.microsoft.com/en-US/sessions/0106b5b1-d727-4240-bb2e-dea325cb8519?source=sessions">their session</a>.
    - date: February 2024
      title: PyRIT release
      image: pyrit-icon-256.png
      imageLayout: side
      imageAlt: The PyRIT project mascot, a raccoon named Roakey, in pirate clothes with a parrot on her shoulder.
      description: <a href="https://www.microsoft.com/en-us/security/blog/2024/02/22/announcing-microsofts-open-automation-framework-to-red-team-generative-ai-systems/?msockid=221eb3d972cd620f327ea74e7345632e">We released PyRIT</a>! Since then, we have been expanding its capabilities to allow for probing multimodal generative AI systems (rather than just text-based ones). Another focus area has been state-of-the-art attack techniques. This space moves pretty fast, but we have added (or are in the process of adding) <a href="https://arxiv.org/abs/2310.08419">PAIR</a>, <a href="https://arxiv.org/abs/2312.02119">Tree of attacks with pruning</a>, <a href="https://arxiv.org/abs/2307.15043">GCG</a>, <a href="https://arxiv.org/abs/2404.01833">Crescendo</a>, <a href="https://www.microsoft.com/en-us/security/blog/2024/06/26/mitigating-skeleton-key-a-new-type-of-generative-ai-jailbreak-technique/?msockid=221eb3d972cd620f327ea74e7345632e">Skeleton Key</a>, and several others. Some of these are our
        own contributions, some of them happened via collaborations or contributions facilitated via the open source repository.
    - date: November 2023
      title: Joined the AI Red Team
      description: I have joined the <a href="https://learn.microsoft.com/en-us/security/ai-red-team/">AI Red Team</a>. See these articles for some background <a href="https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/">[1]</a>, <a href="https://www.wired.com/story/microsoft-ai-red-team/">[2]</a>, and <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming">[3]</a>.
  - timePeriod: December 2021 - November 2023
    location: Remote (MA)
    logo: msft.svg
    logoAlt: Microsoft logo
    title: Responsible AI Engineer on the Azure AI team at Microsoft
    events:
    - date: October 2023
      title: LLM Evaluation Framework paper
      image: lasertag-pipeline.png
      imageAlt: A screenshot from the JMLR website showing the new Fairlearn paper title with authors.
      description: Our new paper is on ArXiv! Titled <a href="https://jmlr.org/papers/v24/23-0389.html">A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications</a>, it talks about some of the ways we have been evaluating LLMs. This was a joint effort of many teams at Microsoft and Microsoft Research. I am particularly happy with the emphasis on input from domain experts. This is merely a tool to help speed up evaluations, but the actual decisions about mitigations and whether a system is deployed remains (and should remain) with humans.
    - date: August 2023
      title: Fairlearn JMLR paper
      image: JMLR.png
      imageAlt: A screenshot from the JMLR website showing the new Fairlearn paper title with authors.
      description: The new <a href="https://jmlr.org/papers/v24/23-0389.html">Fairlearn paper</a> is now in the Journal for Machine Learning Research (Open Source Software section)! It captures our change from being a project under Microsoft governance to being a true open source project with open governance. As of today, half the maintainers are employed by Microsoft (including myself). Also, the focus of the project has shifted significantly since the original whitepaper. Back then, the Python toolkit was the main focus whereas now the educational materials are being prioritized. This aims to acknowledge the sociotechnical nature of fairness.
    - date: December 2021
      title: Responsible AI Dashboard release
      image: rai-dashboard-release.png
      imageAlt: RAI dashboard view of error analysis tool
      description: We released the <a href="https://blogs.microsoft.com/ai-for-business/building-ai-responsibly-from-research-to-practice/">Responsible AI dashboard</a>. As one of the key contributors on the engineering side I am really proud of this milestone. Of course, this is only where it really starts as we can now iterate on the first version. Make sure to <a href="https://responsibleaitoolbox.ai">try it</a> and leave some feedback! The functionality is better captured by the blog and website, but something not mentioned there that I am really excited about is that we pulled this off in the open <a href="https://github.com/microsoft/responsible-ai-toolbox">on GitHub</a>. That means anyone can see what goes into this, ask for features, or even contribute bugfixes. Doing impactful work is awesome, but seeing the recognition in the entire company takes this to a whole different level. For example, I have seen tweets about this by <a href="https://twitter.com/kevin_scott/status/1468279751785828353">Microsoft
        CTO Kevin Scott</a> and <a href="https://twitter.com/erichorvitz/status/1468286435052572678?s=20">Chief Scientific Officer Eric Horvitz</a>.
  - timePeriod: September 2021 - November 2021
    location: Tübingen, Germany
    logo: mpg.svg
    logoAlt: Max Planck logo
    logoLarge: true
    title: Graduate student at the Max Planck Institute for Intelligent Systems
  - timePeriod: July 2017 - August 2021
    location: Cambridge, MA (until 2020), Bellevue, WA (2020-2021)
    logo: msft.svg
    logoAlt: Microsoft logo
    title: Responsible AI Engineer on the Azure ML team at Microsoft
    events:
    - date: November 2019
      title: Fairlearn announced at Ignite
      image: fairlearn-repo.PNG
      imageAlt: fairlearn repository
      description: For a little while now I have been working on <a href="https://www.microsoft.com/en-us/AI/our-approach-to-ai">Responsible AI at Microsoft</a>. Now that <a href="https://myignite.techcommunity.microsoft.com/sessions/81147">Sarah Bird announced our tools at Ignite</a> I can finally point to our tools publicly. A lot of my time over the past months went into <a href="https://github.com/fairlearn/fairlearn">Fairlearn</a>, our open source toolkit for fairness assessment and unfairness mitigation. We just released v0.3.0, so there is a lot more to come in the next months. I will be in Vancouver for NeurIPS in December to demo our tools around fairness and interpretability. Talk to me if you will be there!
    - date: November 2019
      title: Responsible AI reading group
      image: abstraction-fairml.PNG
      imageLayout: side-md
      imageAlt: Abstraction in Fairness-aware Machine Learning
      description: Since fairness is tricky to get right we have been meeting bi-weekly as a Responsible AI reading group. Today I had the honor to lead the discussion about <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913">"Fairness and Abstraction in Sociotechnical Systems"</a> by Andrew D. Selbst, danah boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. I highly encourage everyone to read this paper to avoid the mentioned abstraction traps when building machine learning systems. Maybe this should be part of a mandatory checklist before releasing models... If you are interested in my slides you may download them <a href="https://github.com/romanlutz/romanlutz.github.io/blob/gh-pages/other/FairnessAndAbstractionInSociotechnicalSystems.pdf">here</a>.
    - date: March 2018
      title: MIT Breaking the Mold Hackathon
      description: Participating at <a href="http://www.mitbreakingthemold.com/challenges/">MIT`s Breaking the Mold Hackathon for Inclusion</a> was truly a blessing. With so many truly difficult problems to tackle, it is fantastic to see all the ideas people came up with. Big shoutout to MIT for organizing this, Microsoft for the venue (and encouraging me to go!), and Amazon for sending two inspiring mentors for my team all the way from Seattle! Thanks also to my team for creating a creative environment where everybody could express their ideas. I learned a ton from all of you, and winning 3rd prize tops it all off. I hope everybody takes some time to think about Machine Learning Bias. With ML becoming increasingly prevalent, it is more important than ever to take bias into account.
    - date: July 2017
      title: Joined Azure Machine Learning team
      description: After a year on the Office team, I moved to the Azure Machine Learning team. We are building the infrastructure and services from scratch using lots of open source (e.g., Kubernetes, Linux, .NET core).
  - timePeriod: June 2016 - June 2017
    location: Cambridge, MA
    logo: msft.svg
    logoAlt: Microsoft logo
    title: Software Engineer at Microsoft Office (Docs)
    events:
    - date: May 2017
      title: Hacking Bias in ML workshop
      description: I participated in the <a href="https://www.eventbrite.com/e/new-england-machine-learning-hackathon-hacking-bias-in-ml-tickets-32951771636?aff=NEML">Hacking Bias in ML</a> workshop at Microsoft`s New England Research and Development Center (which happens to be my office, too). My group specifically looked at gender bias in text through word embeddings. We found lots of evidence of gender bias, e.g., some words are generally more used in connection with men ("smart"), some more with women ("lovely"). You can play around with the tool resulting from the workshop <a href="https://mdml.github.io/hacking-bias-in-word-choice/#">here</a>.
    - date: June 2016
      title: Joined Microsoft Office Docs
      description: I have joined the Docs team within Microsoft Office. We enhance collaboration capabilities through the Share feature in all Office apps.
  - timePeriod: Fall 2015 - Spring 2016
    location: Amherst, MA
    logo: umass-amherst.png
    logoAlt: UMass Amherst logo
    logoInvert: true
    title: MS in Computer Science, Focus on Distributed Systems and ML
    events:
    - date: Fall 2015 - Spring 2016
      title: Cache Networks research
      image: cache-networks-simulation-results.png
      imageLayout: side
      imageAlt: Cache Networks Simulation Results
      description: I had the pleasure of working as a Research Assistant in the <a href="http://www-net.cs.umass.edu/networks/people.html">Computer Networking Lab</a> with Professor <a href="https://www.cs.umass.edu/faculty/directory/towsley_donald">Don Towsley</a> and Professor <a href="http://www2.ic.uff.br/~arocha/">Antonio Rocha</a> on the Simulation of Cache Networks. The results still remain to be published, so I will write about it if that happens. Separately, I conducted experiments with cache networks for a graduate seminar on distributed systems. You can download my project report <a href="https://github.com/romanlutz/romanlutz.github.io/blob/gh-pages/other/CacheNetworkSimulation.pdf">here</a>.
    - date: January 2016
      title: Content-Centric Networking paper
      image: ccn.png
      imageLayout: side
      imageAlt: Content Centric Networking
      description: There are several NSF-funded Future Internet Architecture research projects in the US. Their focus is mostly on improving the scalability and efficiency. I am interested in how the different approaches affect (or do not affect) the privacy of users in comparison to the current Internet. My main focus was the feasibility of censorship circumvention. As an example, I picked Content-oriented Networking. See the full paper at <a href="https://arxiv.org/abs/1601.01278">arxiv.org/abs/1601.01278</a>.
    - date: January 2016
      title: NFL play prediction paper
      image: pete-carroll.jpg
      imageLayout: side
      imageAlt: Pete Carroll - coach
      description: 'Based on NFL game data we try to predict the outcome of a play in multiple different ways including Decision and Classification Trees, Nearest Neighbors, Naive Bayes, Linear Discriminant Analysis, Support Vector Machines and Regression, and Artificial Neural Networks. An application of this is the following: by plugging in various play options one could determine the best play for a given situation in real time. While the outcome of a play can be described in many ways we had the most promising results with a newly defined measure that we call "progress". We see this work as a first step to include predictive analysis into NFL playcalling. See the full paper at <a href="https://arxiv.org/abs/1601.00574">arxiv.org/abs/1601.00574</a>; in collaboration with Brendan Teich and Valentin Kassarnig.'
  - timePeriod: June 2015 - August 2015
    location: Eschborn, Germany
    logo: cisco.png
    logoAlt: Cisco Systems logo
    title: Systems Engineering Intern
  - timePeriod: Fall 2014 - Spring 2015
    location: Amherst, MA
    logo: umass-amherst.png
    logoAlt: UMass Amherst logo
    logoInvert: true
    title: Graduate Exchange Student
    events:
    - date: Fall 2014 - Spring 2015
      title: Baden-Württemberg Exchange
      description: I took part in Baden-Württemberg Exchange between University of Ulm and University of Massachusetts Amherst.
    - date: May 2015
      title: Fantasy Football prediction paper
      image: thomas-rawls.jpg
      imageLayout: side
      imageAlt: Thomas Rawls - player
      description: 'New paper! The ubiquity of professional sports and specifically the NFL have lead to an increase in popularity for Fantasy Football. Users have many tools at their disposal: statistics, predictions, rankings of experts and even recommendations of peers. There are issues with all of these, though. Especially since many people pay money to play, the prediction tools should be enhanced as they provide unbiased and easy-to-use assistance for users. This paper provides and discusses approaches to predict Fantasy Football scores of Quarterbacks with relatively limited data. See the full paper at <a href="https://arxiv.org/abs/1505.06918">arxiv.org/abs/1505.06918</a>.'
  - timePeriod: Fall 2011 - Summer 2014
    location: Ulm, Germany
    logo: uni-ulm.svg
    logoAlt: Uni Ulm logo
    logoInvert: true
    title: University of Ulm
    events:
    - date: Fall 2011 - Summer 2014
      title: BSc in Computer Science
      description: After a year of studying in the Mathematics Bachelor`s program with a minor in Computer Science I decided to swap major and minor. I still graduated with a BSc in Computer Science with honors. The courses covered basics in Systems, AI, and Theory.
    - date: '2014'
      title: 'Bachelor`s thesis: Adaptive Large Neighborhood Search'
      image: alns.png
      imageAlt: Adaptive Large Neighborhood Search - Destroy and Repair
      description: The goal of my Bachelor`s thesis was to implement the Adaptive Large Neighborhood Search (ALNS) heuristic and possibly come up with improvements. ALNS was described first by S. Ropke and D. Pisinger and is based on P. Shaw`s Large Neighborhood Search. The idea is that some problems are difficult to solve with basic local search algorithms because of a tightly constrained search space. Small changes to a solution will rarely bring improvements. As a consequence, LNS and ALNS change larger parts based on different heuristics. For this thesis, I received the innoWake Award 2015. <a href="http://www.innowake.com">innoWake</a> was a software modernization company based in Austin, TX and had a number of branch offices including one in Germany. They have since been acquired by Deloitte.
    - date: '2013'
      title: Teaching Assistant for Algorithms and Data Structures
      image: graph.svg
      imageLayout: side
      imageInvert: true
      imageAlt: Graph from http://commons.wikimedia.org/wiki/File:Dinic_algorithm_Gf2.svg, public domain
      description: As a teaching assistant for Prof. Jacobo Toran, Gunnar Völkel and Dominikus Krüger, I explained the solutions to weekly assignments to a group of 20 students whose work I also graded. In addition to that, I often gave a review of the material presented in class. It made me very happy to see the attendance rate constantly high throughout the semester and especially the positive feedback at the end of the course.
    - date: '2013'
      title: 'Nature-Inspired Metaheuristics: Artificial Bee Colony'
      image: bees.jpg
      imageLayout: side
      imageAlt: Bees from https://pixabay.com/en/queen-cup-honeycomb-honey-bee-337695/, CC0 Public Domain
      description: As part of a seminar at Uni Ulm, I implemented and evaluated the Artificial Bee Colony (ABC) meta-heuristic by D. Karaboga. ABC is a nature-inspired metaheuristic that projects the foraging behavior of bees on an algorithm in order to solve optimization problems. The idea behind such approaches is that many kinds of behavior of animals, bacteria etc. in nature have adapted to their specific environment due to evolution — in a way, an optimization process has taken place.
    - date: '2012'
      title: Concurrent Programming in Java seminar
      image: traffic.jpg
      imageLayout: side
      imageAlt: Traffic from https://pixabay.com/en/traffic-highway-lights-night-road-332857/, CC0 Public Domain
      description: Under the guidance of Christian Spann, I read up on different ways to implement concurrent programs in Java, from Threads, Runnables and Executors to thread-safe versions of data structures. Finally, I presented the different approaches and techniques in a seminar talk.
maps:
  - id: us-map
    title: Map of the US states I have visited
    content:
      - 'green = visited, light green = transit only, dark gray = not visited'
    mapConfiguration:
      scope: usa
      labels: true
      places:
        - { name: AK, visited: true }
        - { name: AZ, visited: false }
        - { name: CA, visited: true }
        - { name: CO, visited: true }
        - { name: CT, visited: true }
        - { name: DC, visited: true }
        - { name: DE, visited: true }
        - { name: FL, visited: true }
        - { name: ID, visited: true }
        - { name: IL, visited: false }
        - { name: MA, visited: true }
        - { name: MD, visited: true }
        - { name: ME, visited: true }
        - { name: MN, visited: false }
        - { name: MT, visited: true }
        - { name: NH, visited: true }
        - { name: NJ, visited: true }
        - { name: NY, visited: true }
        - { name: OR, visited: true }
        - { name: PA, visited: true }
        - { name: RI, visited: true }
        - { name: SD, visited: true }
        - { name: UT, visited: true }
        - { name: VT, visited: true }
        - { name: WA, visited: true }
        - { name: WY, visited: true }
  - id: world-map
    title: Map of the countries I have visited
    mapConfiguration:
      scope: world
      labels: false
      places:
        - { name: ARE, visited: false }
        - { name: AUT, visited: true }
        - { name: BEL, visited: false }
        - { name: BHS, visited: true }
        - { name: CAN, visited: true }
        - { name: CHE, visited: true }
        - { name: DEU, visited: true }
        - { name: ESP, visited: true }
        - { name: GBR, visited: true }
        - { name: FIN, visited: true }
        - { name: FRA, visited: true }
        - { name: HUN, visited: true }
        - { name: ISL, visited: false }
        - { name: IND, visited: true }
        - { name: ITA, visited: true }
        - { name: MEX, visited: true }
        - { name: MLT, visited: true }
        - { name: NLD, visited: true }
        - { name: POL, visited: true }
        - { name: SMR, visited: true }
        - { name: USA, visited: true }
        - { name: VAT, visited: true }
---
